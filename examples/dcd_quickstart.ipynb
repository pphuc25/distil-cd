{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1415c86-c111-4197-a3fe-2c8903bdaa4f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Distillation Contrastive Decoding: Improving LLMs Reasoning with Contrastive Decoding and Distillation\n",
    "\n",
    "TL;DR: Distillation Contrastive Decoding work introduces an innovative decoding approach that enhances language model reasoning by leveraging the concept of contrastive decoding (Innovates upon the traditional contrastive decoding and Chain-of-Thought (CoT) prompting methods). It operates by contrasting the logits from a expert model (Answer right) with Amateur model (Answer wrong). Notably, both models are the same.\n",
    "\n",
    "<p align=\"center\"><img src=\"https://github.com/pphuc25/distil-cd/blob/main/assets/figure1-method.jpg?raw=true\" width=\"800\"></p>\n",
    "\n",
    "**Resources**:\n",
    "<!-- - Read our paper on [arXiv](#) for a deep dive into our methodology. -->\n",
    "- Explore the codebase and contribute on GitHub: [distil-cd](https://github.com/pphuc25/distil-cd/tree/main).\n",
    "<!-- - Join the conversation on Twitter: [Twitter Discussion](#). -->\n",
    "\n",
    "> **Access Requirement**: The following demonstration employs the [Gemma 2b model by Google](https://huggingface.co/google/gemma-2b), which requires authorized access. Please ensure you have the necessary permissions on Hugging Face to interact with the model before proceeding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60c4d42-2a47-4cb1-ae78-8cbb1054b5f1",
   "metadata": {},
   "source": [
    "## Login HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50b99b6e-fd84-413c-9afd-99c60e0c792a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889324b3-e9be-47c0-a2e8-9635c9750b02",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "1. Git clone our repo\n",
    "2. Install the customized transformers package (which supports a our new decoding method)\n",
    "3. Install other requirements from pip (upgrade transformers upto date to apply newest mdoel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be0bc953-aa19-4a73-b8d7-c25d91587073",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'distil-cd'...\n",
      "remote: Enumerating objects: 605, done.\u001b[K\n",
      "remote: Counting objects: 100% (605/605), done.\u001b[K\n",
      "remote: Compressing objects: 100% (128/128), done.\u001b[K\n",
      "remote: Total 605 (delta 486), reused 586 (delta 470), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (605/605), 1.39 MiB | 16.89 MiB/s, done.\n",
      "Resolving deltas: 100% (486/486), done.\n",
      "Obtaining file:///notebooks/distil-cd/examples/distil-cd\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (from dcd==0.0.1) (4.21.3)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from dcd==0.0.1) (1.5.0)\n",
      "Collecting accelerate\n",
      "  Using cached accelerate-0.27.2-py3-none-any.whl (279 kB)\n",
      "Collecting jsonlines\n",
      "  Using cached jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from accelerate->dcd==0.0.1) (1.23.4)\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.9/dist-packages (from accelerate->dcd==0.0.1) (0.12.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from accelerate->dcd==0.0.1) (23.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from accelerate->dcd==0.0.1) (5.9.4)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from accelerate->dcd==0.0.1) (5.4.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.9/dist-packages (from accelerate->dcd==0.0.1) (1.12.1+cu116)\n",
      "Collecting safetensors>=0.3.1\n",
      "  Using cached safetensors-0.4.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Collecting attrs>=19.2.0\n",
      "  Using cached attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->dcd==0.0.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->dcd==0.0.1) (2022.7.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers->dcd==0.0.1) (0.12.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers->dcd==0.0.1) (4.64.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers->dcd==0.0.1) (2.28.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers->dcd==0.0.1) (3.9.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers->dcd==0.0.1) (2022.10.31)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->accelerate->dcd==0.0.1) (4.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas->dcd==0.0.1) (1.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->transformers->dcd==0.0.1) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers->dcd==0.0.1) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers->dcd==0.0.1) (2019.11.28)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers->dcd==0.0.1) (2.8)\n",
      "Building wheels for collected packages: dcd\n",
      "  Building editable for dcd (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dcd: filename=dcd-0.0.1-0.editable-py3-none-any.whl size=1207 sha256=2c0b132f37c79543a6083fcf62007446e25a9ac36fd480b359475fd9d9187ea4\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-yu3fyarl/wheels/c5/b9/d2/8d9ba713090fd145fc8249cdad8f616d1912e61cf66d238e68\n",
      "Successfully built dcd\n",
      "Installing collected packages: safetensors, attrs, jsonlines, accelerate, dcd\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 18.2.0\n",
      "    Uninstalling attrs-18.2.0:\n",
      "      Successfully uninstalled attrs-18.2.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gradient 2.0.6 requires attrs<=19, but you have attrs 23.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed accelerate-0.27.2 attrs-23.2.0 dcd-0.0.1 jsonlines-4.0.0 safetensors-0.4.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.21.3)\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.38.1-py3-none-any.whl (8.5 MB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.23.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (5.4.1)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3\n",
      "  Using cached huggingface_hub-0.20.3-py3-none-any.whl (330 kB)\n",
      "Collecting tokenizers<0.19,>=0.14\n",
      "  Using cached tokenizers-0.15.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.9.0)\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Using cached fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers) (2.8)\n",
      "Installing collected packages: fsspec, huggingface-hub, tokenizers, transformers\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.1.0\n",
      "    Uninstalling fsspec-2023.1.0:\n",
      "      Successfully uninstalled fsspec-2023.1.0\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.12.0\n",
      "    Uninstalling huggingface-hub-0.12.0:\n",
      "      Successfully uninstalled huggingface-hub-0.12.0\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.12.1\n",
      "    Uninstalling tokenizers-0.12.1:\n",
      "      Successfully uninstalled tokenizers-0.12.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.21.3\n",
      "    Uninstalling transformers-4.21.3:\n",
      "      Successfully uninstalled transformers-4.21.3\n",
      "Successfully installed fsspec-2024.2.0 huggingface-hub-0.20.3 tokenizers-0.15.2 transformers-4.38.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/pphuc25/distil-cd.git\n",
    "!cd distil-cd && pip install -e .\n",
    "!pip install transformers -U"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ffed07-a02f-411a-ae53-f0d0de4b32e9",
   "metadata": {},
   "source": [
    "### Register Decoding Method:\n",
    "\n",
    "**Troubleshooting Note**: If you encounter any issues executing this setup cell, please restart the runtime/kernel. This can resolve initial setup conflicts. To do so in Google Colab, go to the menu bar and select `Runtime` > `Restart session`, and then run this cell again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "790bf973-604d-48ff-9e41-92b633e417e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Registry DCD method \n",
    "from dcd import dcd_pipeline_registry\n",
    "dcd_pipeline_registry()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3c362f-e3ee-4cb3-afe2-4b8ee6b86f66",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "For this colab example, we will use model [Gemma 2b](https://huggingface.co/google/gemma-2b) of Google. The example will show the different of run version greedy and DCD dropout with contrastive cot prompt is synthetic demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243cc63d-1dfd-4fc9-a970-58d3861c2e9e",
   "metadata": {},
   "source": [
    "### Import libraries and Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a05d44f4-b4c1-4fe5-802e-14096fff38ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig\n",
    "from dcd import set_stop_words, create_prompt, create_prompt_student\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cbf3c62-fa26-4228-9517-1cfc9b15e0c0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55ab96e4bc2a4db9812c1cf94cca0965",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"google/gemma-2b\", device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2b\", device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dbb8c2-9645-4880-a768-899cc49b935a",
   "metadata": {},
   "source": [
    "### Setup configs and question\n",
    "\n",
    "For use DCD, you must set the beam_size to 1 seen it's the variant of greedy method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3370f05-3d7b-4b31-be38-896f482311a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added stop word:  Q: with the ids [235292]\n",
      "Added stop word:  \\end{code} with the ids [615, 235282, 2564, 235270]\n",
      "Added stop word:  </s> with the ids [235256, 235313]\n",
      "Added stop word:  Wrong explanation: with the ids [15844, 235292]\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "beam_size = 1\n",
    "max_length = 250\n",
    "\n",
    "alpha_coef = 0.1\n",
    "beta_coef = 0.7\n",
    "dropout_rate = 0.2\n",
    "\n",
    "type_prompt = 4  # The synthetic demonstration prompt for arithmetic problems\n",
    "\n",
    "stopping_criteria = set_stop_words(tokenizer=tokenizer, stop_words=[\"Q:\", \"\\end{code}\", \"</s>\", \"Wrong explanation:\"])\n",
    "\n",
    "generation_config = GenerationConfig(\n",
    "    do_sample=False,\n",
    "    num_beams=beam_size,\n",
    "    pad_token_id=0,\n",
    "    eos_token_id=0,\n",
    ")\n",
    "\n",
    "class Args:\n",
    "    def __init__(self) -> None:\n",
    "        self.prompt_file = 'gsm8k'\n",
    "        self.data_name = \"gsm8k\"\n",
    "        self.cot_flag = True\n",
    "        self.direct_answer_trigger_for_fewshot = 'The answer is'\n",
    "\n",
    "args_prompt = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "111dbdce-fcd0-473e-9f5c-b37d2bb717df",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Josh decides to try flipping a house. He buys a house for $80,000 and then puts in $50,000 in repairs. This increased the value of the house by 150%. How much profit did he make?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea99214-16eb-4fc2-9220-eaeea176826d",
   "metadata": {},
   "source": [
    "### Greedy Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01cb087c-6dfb-40f7-aab4-43e49bd36169",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_formated = \"Q: \" + question + \"\\n\" + \"A:\"\n",
    "inputs = tokenizer(create_prompt(args_prompt, data_name=args_prompt.data_name) + question_formated, return_tensors=\"pt\")\n",
    "input_ids = inputs[\"input_ids\"].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09bbcf7e-25d4-4f1e-9245-65b848f4edb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_args_greedy = dict(\n",
    "    generation_config=generation_config,\n",
    "    return_dict_in_generate=True,\n",
    "    output_scores=True,\n",
    "    max_new_tokens=max_length,\n",
    "    stopping_criteria=stopping_criteria,\n",
    "    min_tokens_to_keep=2 if beam_size > 1 else 1,\n",
    "    dropout_rate=dropout_rate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b8b89b1-f9f9-40a0-bd8c-0aa07d3fc7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of greedy: Josh bought the house for $80,000. Then he put in $50,000 in repairs. So the value of the house increased by 150%. 150% of $80,000 is 150/100 * 80,000 = 120,000. So the value of the house increased by 120,000. 80,000 + 120,000 = 200,000. The answer is 200,000.\n"
     ]
    }
   ],
   "source": [
    "output_sequences = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    **inputs_args_greedy)\n",
    "\n",
    "s_greedy = output_sequences.sequences[0]\n",
    "output_greedy = tokenizer.decode(s_greedy, skip_special_tokens=True)\n",
    "\n",
    "output_formated_greedy = output_greedy.split(\"A: \")[-1].replace(\"\\n\\nQ:\", \"\")\n",
    "print(f\"Output of greedy: {output_formated_greedy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93298f7e-db54-48b4-9799-afbab6b76ad3",
   "metadata": {},
   "source": [
    "### Distillation Contrastive Decoding with Dropout Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9c7d475-ca7b-4f49-9b59-f376cfc0af6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_formated = \"Q: \" + question + \"\\n\" + \"A:\"\n",
    "inputs = tokenizer(create_prompt(args_prompt, data_name=args_prompt.data_name) + question_formated, return_tensors=\"pt\")\n",
    "input_ids = inputs[\"input_ids\"].to(device)\n",
    "\n",
    "inputs_student = tokenizer(create_prompt_student(args_prompt, type=type_prompt, data_name=args_prompt.data_name) + question_formated, return_tensors=\"pt\")\n",
    "input_ids_student = inputs_student[\"input_ids\"].to(device)\n",
    "attention_mask_student = inputs_student[\"attention_mask\"].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cc433f6-9384-4407-849e-07ecaceb2f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_args_dcd = dict(\n",
    "    generation_config=generation_config,\n",
    "    return_dict_in_generate=True,\n",
    "    output_scores=True,\n",
    "    max_new_tokens=max_length,\n",
    "    stopping_criteria=stopping_criteria,\n",
    "\n",
    "    # DCD parameters of dropout\n",
    "    alpha_coef=alpha_coef,\n",
    "    beta_coef=beta_coef,\n",
    "    min_tokens_to_keep=2 if beam_size > 1 else 1,\n",
    "    teacher_student=True,\n",
    "    dropout_rate=dropout_rate\n",
    ")\n",
    "\n",
    "model_kwargs_student = dict(\n",
    "    attention_mask=attention_mask_student\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5b1fc57-5a75-4161-a97b-66368d617330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of DCD: Josh started with 80,000 dollars. He spent 50,000 dollars on repairs. So he had 80,000 - 50,000 = 30,000 dollars left. Then the house was sold for 30,000 dollars more. 30,000 + 30,000 is 60,000. The answer is 60,000.\n"
     ]
    }
   ],
   "source": [
    "output_sequences = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    input_ids_student=input_ids_student,\n",
    "    model_kwargs_student=model_kwargs_student,\n",
    "    **inputs_args_dcd)\n",
    "\n",
    "s_dcd = output_sequences.sequences[0]\n",
    "output_dcd = tokenizer.decode(s_dcd, skip_special_tokens=True)\n",
    "output_formated_dcd = output_dcd.split(\"A: \")[-1].replace(\"\\n\\nQ:\", \"\")\n",
    "print(f\"Output of DCD: {output_formated_dcd}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
